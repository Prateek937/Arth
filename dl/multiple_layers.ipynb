{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cubic-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporated-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broad-translation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ongoing-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "geological-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "optimum-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "italian-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard','IsActiveMember', 'EstimatedSalary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "subsequent-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get dummy variable for categorical variable\n",
    "geo = pd.get_dummies(dataset['Geography'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "express-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = pd.get_dummies(dataset['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "broken-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat column wise (axis = 1)\n",
    "X = pd.concat([X, geo, gender], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "binary-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "italian-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "republican-rugby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "compliant-feature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "first-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "mounted-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "martial-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/arth1/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m                 \u001b[0;34m'Build the model first by calling build() '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m                 \u001b[0;34m'or calling fit() with some data. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "essential-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "matched-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add first layer : hidden layer\n",
    "# units : number of neurons in one layer\n",
    "# activation : activation function \n",
    "# input shape/dim: number of input columns\n",
    "model.add(Dense(units = 8, activation='relu', input_dim=11 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "massive-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 96        \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "higher-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding second layers\n",
    "model.add(Dense(units = 6, activation = 'relu' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "miniature-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 150\n",
      "Trainable params: 150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "compact-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding third layer\n",
    "model.add(Dense(units = 6, activation = 'relu' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "powerful-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth layer\n",
    "model.add(Dense(units = 6, activation = 'relu' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "miniature-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last layer will have only one output, and sigmoid as activation function\n",
    "# because we need binary classification : sigmoid function\n",
    "model.add(Dense(units = 1, activation = 'sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "portable-corps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ambient-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "intermediate-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss : checking errors: binary_crossentropy function\n",
    "# learning_rate hyperparameter\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "modified-deviation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.34670508,  0.01113838,  0.0753026 , -0.08457398,  0.4737441 ,\n",
       "          0.1817894 ,  0.27590716,  0.3379057 ],\n",
       "        [-0.1868605 , -0.3498141 , -0.00736099, -0.0231576 ,  0.4708565 ,\n",
       "         -0.28783306,  0.5162913 , -0.21998   ],\n",
       "        [ 0.4703893 ,  0.12360257, -0.23922178,  0.4296109 ,  0.4590302 ,\n",
       "          0.13292003, -0.04884392,  0.2629059 ],\n",
       "        [ 0.09210914,  0.2874381 ,  0.0657509 , -0.031618  ,  0.00832427,\n",
       "         -0.42030722,  0.5300184 , -0.37244338],\n",
       "        [ 0.528837  , -0.4060235 ,  0.48367935,  0.22051233,  0.37176156,\n",
       "          0.30666202, -0.21457568,  0.03818864],\n",
       "        [-0.47611055,  0.4749015 ,  0.5513025 ,  0.2705186 ,  0.46326166,\n",
       "         -0.51713765,  0.5039514 , -0.09428698],\n",
       "        [ 0.3413691 ,  0.28751165,  0.41002268, -0.2709878 ,  0.23616219,\n",
       "         -0.27865922,  0.23160636,  0.11336809],\n",
       "        [-0.16374245,  0.0968101 ,  0.34639114, -0.00968778,  0.16401994,\n",
       "          0.3374188 ,  0.48829228, -0.15794596],\n",
       "        [ 0.00564897,  0.31983423, -0.37034205, -0.02984142,  0.3051852 ,\n",
       "          0.0615201 ,  0.47668248, -0.4528604 ],\n",
       "        [ 0.14808184,  0.5171204 ,  0.10830718,  0.21486652,  0.07319361,\n",
       "         -0.4342395 , -0.1213119 ,  0.05644149],\n",
       "        [-0.36124295,  0.04562587,  0.44319242, -0.13188249,  0.22715622,\n",
       "          0.08350015, -0.0521639 ,  0.32701033]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.06080222, -0.36477003,  0.4773667 , -0.61191696,  0.21766263,\n",
       "          0.24706262],\n",
       "        [-0.29476026,  0.3596568 , -0.40211332, -0.58946586,  0.05641305,\n",
       "          0.2225697 ],\n",
       "        [ 0.26324427, -0.12866086, -0.5886493 ,  0.5148808 , -0.4911031 ,\n",
       "         -0.2523226 ],\n",
       "        [-0.32303864,  0.44618106,  0.05448681,  0.06761861,  0.51852334,\n",
       "          0.14321327],\n",
       "        [ 0.04350257,  0.5060214 ,  0.2397691 , -0.09702611,  0.37208462,\n",
       "          0.27776736],\n",
       "        [ 0.20139176, -0.26544783,  0.186827  , -0.44089198,  0.3421716 ,\n",
       "         -0.32947528],\n",
       "        [ 0.6332613 , -0.2655822 , -0.1907776 , -0.27626023, -0.34365204,\n",
       "         -0.34101957],\n",
       "        [-0.6072823 ,  0.12203145,  0.24835205, -0.1929273 ,  0.23546034,\n",
       "          0.22779733]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.520142  ,  0.22843271, -0.36818257, -0.18683594,  0.42800194,\n",
       "         -0.2760787 ],\n",
       "        [-0.47511637,  0.37896186,  0.09204352,  0.22218943, -0.205289  ,\n",
       "          0.46524316],\n",
       "        [ 0.25414854,  0.15289783, -0.21520838, -0.5627813 , -0.32578588,\n",
       "          0.36208743],\n",
       "        [ 0.54818755, -0.07731909, -0.5047822 ,  0.1770727 , -0.19469923,\n",
       "          0.12188309],\n",
       "        [ 0.4428342 ,  0.5521355 , -0.57358354, -0.6132444 ,  0.05511576,\n",
       "         -0.4283197 ],\n",
       "        [ 0.28526455,  0.47079247,  0.60820967,  0.21231157, -0.36253706,\n",
       "          0.4164707 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.24539512, -0.01670194, -0.5224161 ,  0.24662918, -0.40075904,\n",
       "          0.25513577],\n",
       "        [-0.37799957, -0.29035687,  0.07850236, -0.35457265, -0.06147188,\n",
       "         -0.1978609 ],\n",
       "        [ 0.38006252, -0.20750916, -0.22253418, -0.5158044 , -0.11157769,\n",
       "          0.6311868 ],\n",
       "        [-0.67948574, -0.39068037,  0.6976052 , -0.47074252,  0.3558269 ,\n",
       "          0.06389159],\n",
       "        [-0.63571286,  0.3016209 , -0.41746908,  0.12371635,  0.22386062,\n",
       "          0.5023026 ],\n",
       "        [ 0.5246332 , -0.01059085, -0.36083317,  0.5209523 , -0.28994367,\n",
       "         -0.6186884 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.01837599],\n",
       "        [ 0.22899783],\n",
       "        [-0.62669134],\n",
       "        [-0.43403733],\n",
       "        [-0.82230884],\n",
       "        [-0.2794419 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "finnish-threshold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_3',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_6',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'units': 8,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cosmetic-zealand",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 1549.2403\n",
      "Epoch 2/200\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 1540.5156\n",
      "Epoch 3/200\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 1531.8088\n",
      "Epoch 4/200\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 1523.1065\n",
      "Epoch 5/200\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 1514.4493\n",
      "Epoch 6/200\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 1505.7997\n",
      "Epoch 7/200\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 1497.1672\n",
      "Epoch 8/200\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 1488.5697\n",
      "Epoch 9/200\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 1479.9971\n",
      "Epoch 10/200\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 1471.4495\n",
      "Epoch 11/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1462.9606\n",
      "Epoch 12/200\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 1454.5048\n",
      "Epoch 13/200\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 1446.0789\n",
      "Epoch 14/200\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 1437.6929\n",
      "Epoch 15/200\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 1429.3482\n",
      "Epoch 16/200\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 1421.0193\n",
      "Epoch 17/200\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 1412.7245\n",
      "Epoch 18/200\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 1404.4518\n",
      "Epoch 19/200\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 1396.2036\n",
      "Epoch 20/200\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 1387.9857\n",
      "Epoch 21/200\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 1379.8105\n",
      "Epoch 22/200\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 1371.6644\n",
      "Epoch 23/200\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 1363.5436\n",
      "Epoch 24/200\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 1355.4313\n",
      "Epoch 25/200\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 1347.3326\n",
      "Epoch 26/200\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 1339.2686\n",
      "Epoch 27/200\n",
      "8000/8000 [==============================] - 2s 206us/step - loss: 1331.2406\n",
      "Epoch 28/200\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 1323.2594\n",
      "Epoch 29/200\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 1315.2934\n",
      "Epoch 30/200\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 1307.3557\n",
      "Epoch 31/200\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 1299.4551\n",
      "Epoch 32/200\n",
      "8000/8000 [==============================] - 1s 154us/step - loss: 1291.5770\n",
      "Epoch 33/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 1283.7362\n",
      "Epoch 34/200\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 1275.9276\n",
      "Epoch 35/200\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 1268.1345\n",
      "Epoch 36/200\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 1260.3527\n",
      "Epoch 37/200\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 1252.6121\n",
      "Epoch 38/200\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1244.8874\n",
      "Epoch 39/200\n",
      "8000/8000 [==============================] - 1s 125us/step - loss: 1237.1969\n",
      "Epoch 40/200\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 1229.5251\n",
      "Epoch 41/200\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 1221.8837\n",
      "Epoch 42/200\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 1214.2445\n",
      "Epoch 43/200\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 1206.6302\n",
      "Epoch 44/200\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 1199.0555\n",
      "Epoch 45/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 1191.4991\n",
      "Epoch 46/200\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 1183.9746\n",
      "Epoch 47/200\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 1176.4720\n",
      "Epoch 48/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1169.0153\n",
      "Epoch 49/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 1161.5797\n",
      "Epoch 50/200\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 1154.1687\n",
      "Epoch 51/200\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 1146.7649\n",
      "Epoch 52/200\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 1139.3669\n",
      "Epoch 53/200\n",
      "8000/8000 [==============================] - 1s 136us/step - loss: 1132.0174\n",
      "Epoch 54/200\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 1124.6887\n",
      "Epoch 55/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 1117.3815\n",
      "Epoch 56/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 1110.1044\n",
      "Epoch 57/200\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1102.8565\n",
      "Epoch 58/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1095.6455\n",
      "Epoch 59/200\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 1088.4802\n",
      "Epoch 60/200\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 1081.3300\n",
      "Epoch 61/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 1074.2029\n",
      "Epoch 62/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1067.0924\n",
      "Epoch 63/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 1059.9886\n",
      "Epoch 64/200\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 1052.9139\n",
      "Epoch 65/200\n",
      "8000/8000 [==============================] - 1s 171us/step - loss: 1045.8555\n",
      "Epoch 66/200\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 1038.8249\n",
      "Epoch 67/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 1031.8186\n",
      "Epoch 68/200\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 1024.8384\n",
      "Epoch 69/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 1017.8677\n",
      "Epoch 70/200\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 1010.9146\n",
      "Epoch 71/200\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 1003.9922\n",
      "Epoch 72/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 997.1042\n",
      "Epoch 73/200\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 990.2418\n",
      "Epoch 74/200\n",
      "8000/8000 [==============================] - 1s 172us/step - loss: 983.3973\n",
      "Epoch 75/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 976.5926\n",
      "Epoch 76/200\n",
      "8000/8000 [==============================] - 1s 125us/step - loss: 969.8214\n",
      "Epoch 77/200\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 963.0621\n",
      "Epoch 78/200\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 956.3248\n",
      "Epoch 79/200\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 949.6179\n",
      "Epoch 80/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 942.9248\n",
      "Epoch 81/200\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 936.2601\n",
      "Epoch 82/200\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 929.6092\n",
      "Epoch 83/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 922.9879\n",
      "Epoch 84/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 916.3797\n",
      "Epoch 85/200\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 909.7823\n",
      "Epoch 86/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 903.2102\n",
      "Epoch 87/200\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 896.6644\n",
      "Epoch 88/200\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 890.1441\n",
      "Epoch 89/200\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 883.6600\n",
      "Epoch 90/200\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 877.2045\n",
      "Epoch 91/200\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 870.7709\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 126us/step - loss: 864.3559\n",
      "Epoch 93/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 857.9478\n",
      "Epoch 94/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 851.5592\n",
      "Epoch 95/200\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 845.1909\n",
      "Epoch 96/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 838.8541\n",
      "Epoch 97/200\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 832.5268\n",
      "Epoch 98/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 826.2200\n",
      "Epoch 99/200\n",
      "8000/8000 [==============================] - 1s 134us/step - loss: 819.9586\n",
      "Epoch 100/200\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 813.7292\n",
      "Epoch 101/200\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 807.5298\n",
      "Epoch 102/200\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 801.3618\n",
      "Epoch 103/200\n",
      "8000/8000 [==============================] - 1s 129us/step - loss: 795.2067\n",
      "Epoch 104/200\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 789.0739\n",
      "Epoch 105/200\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 782.9755\n",
      "Epoch 106/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 776.8920\n",
      "Epoch 107/200\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 770.8234\n",
      "Epoch 108/200\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 764.7614\n",
      "Epoch 109/200\n",
      "8000/8000 [==============================] - 1s 135us/step - loss: 758.7193\n",
      "Epoch 110/200\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 752.7113\n",
      "Epoch 111/200\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 746.7232\n",
      "Epoch 112/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 740.7576\n",
      "Epoch 113/200\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 734.8193\n",
      "Epoch 114/200\n",
      "8000/8000 [==============================] - 1s 126us/step - loss: 728.9052\n",
      "Epoch 115/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 723.0239\n",
      "Epoch 116/200\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 717.1578\n",
      "Epoch 117/200\n",
      "8000/8000 [==============================] - 1s 137us/step - loss: 711.3166\n",
      "Epoch 118/200\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 705.4967\n",
      "Epoch 119/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 699.7105\n",
      "Epoch 120/200\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 693.9368\n",
      "Epoch 121/200\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 688.1852\n",
      "Epoch 122/200\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 682.4537\n",
      "Epoch 123/200\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 676.7356\n",
      "Epoch 124/200\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 671.0458\n",
      "Epoch 125/200\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 665.3731\n",
      "Epoch 126/200\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 659.7219\n",
      "Epoch 127/200\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 654.0884\n",
      "Epoch 128/200\n",
      "8000/8000 [==============================] - 1s 176us/step - loss: 648.4719\n",
      "Epoch 129/200\n",
      "8000/8000 [==============================] - 1s 123us/step - loss: 642.8814\n",
      "Epoch 130/200\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 637.3199\n",
      "Epoch 131/200\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 631.7797\n",
      "Epoch 132/200\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 626.2633\n",
      "Epoch 133/200\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 620.7767\n",
      "Epoch 134/200\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 615.3113\n",
      "Epoch 135/200\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 609.8629\n",
      "Epoch 136/200\n",
      "8000/8000 [==============================] - 1s 96us/step - loss: 604.4456\n",
      "Epoch 137/200\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 599.0532\n",
      "Epoch 138/200\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 593.6848\n",
      "Epoch 139/200\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 588.3328\n",
      "Epoch 140/200\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 583.0168\n",
      "Epoch 141/200\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 577.7226\n",
      "Epoch 142/200\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 572.4435\n",
      "Epoch 143/200\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 567.1827\n",
      "Epoch 144/200\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 561.9513\n",
      "Epoch 145/200\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 556.7385\n",
      "Epoch 146/200\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 551.5360\n",
      "Epoch 147/200\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 546.3613\n",
      "Epoch 148/200\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 541.1982\n",
      "Epoch 149/200\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 536.0673\n",
      "Epoch 150/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 530.9440\n",
      "Epoch 151/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 525.8300\n",
      "Epoch 152/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 520.7348\n",
      "Epoch 153/200\n",
      "8000/8000 [==============================] - 2s 191us/step - loss: 515.6688\n",
      "Epoch 154/200\n",
      "8000/8000 [==============================] - 1s 186us/step - loss: 510.6291\n",
      "Epoch 155/200\n",
      "8000/8000 [==============================] - 1s 130us/step - loss: 505.6014\n",
      "Epoch 156/200\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 500.5879\n",
      "Epoch 157/200\n",
      "8000/8000 [==============================] - 1s 186us/step - loss: 495.5947\n",
      "Epoch 158/200\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 490.6215\n",
      "Epoch 159/200\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 485.6704\n",
      "Epoch 160/200\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 480.7390\n",
      "Epoch 161/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 475.8311\n",
      "Epoch 162/200\n",
      "8000/8000 [==============================] - 2s 189us/step - loss: 470.9454\n",
      "Epoch 163/200\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 466.0915\n",
      "Epoch 164/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 461.2609\n",
      "Epoch 165/200\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 456.4494\n",
      "Epoch 166/200\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 451.6485\n",
      "Epoch 167/200\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 446.8731\n",
      "Epoch 168/200\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 442.1277\n",
      "Epoch 169/200\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 437.4058\n",
      "Epoch 170/200\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 432.7000\n",
      "Epoch 171/200\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 428.0100\n",
      "Epoch 172/200\n",
      "8000/8000 [==============================] - 1s 133us/step - loss: 423.3383\n",
      "Epoch 173/200\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 418.6866\n",
      "Epoch 174/200\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 414.0467\n",
      "Epoch 175/200\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 409.4288\n",
      "Epoch 176/200\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 404.8303\n",
      "Epoch 177/200\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 400.2562\n",
      "Epoch 178/200\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 395.7023\n",
      "Epoch 179/200\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 391.1643\n",
      "Epoch 180/200\n",
      "8000/8000 [==============================] - 1s 128us/step - loss: 386.6416\n",
      "Epoch 181/200\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 382.1440\n",
      "Epoch 182/200\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 377.6660\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 103us/step - loss: 373.2108\n",
      "Epoch 184/200\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 368.7754\n",
      "Epoch 185/200\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 364.3591\n",
      "Epoch 186/200\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 359.9495\n",
      "Epoch 187/200\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 355.5550\n",
      "Epoch 188/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 351.1849\n",
      "Epoch 189/200\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 346.8327\n",
      "Epoch 190/200\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 342.5055\n",
      "Epoch 191/200\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 338.1921\n",
      "Epoch 192/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 333.8975\n",
      "Epoch 193/200\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 329.6208\n",
      "Epoch 194/200\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 325.3680\n",
      "Epoch 195/200\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 321.1393\n",
      "Epoch 196/200\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 316.9304\n",
      "Epoch 197/200\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 312.7298\n",
      "Epoch 198/200\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 308.5456\n",
      "Epoch 199/200\n",
      "8000/8000 [==============================] - 1s 100us/step - loss: 304.3766\n",
      "Epoch 200/200\n",
      "8000/8000 [==============================] - 1s 127us/step - loss: 300.2316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f0f48ad4550>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat learning: epochs\n",
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "expensive-signature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1549.24031149292,\n",
       "  1540.5156468811035,\n",
       "  1531.8088204040528,\n",
       "  1523.1065329589844,\n",
       "  1514.4492524414063,\n",
       "  1505.7997321166993,\n",
       "  1497.1672133789064,\n",
       "  1488.5697400512695,\n",
       "  1479.997147216797,\n",
       "  1471.4495061645507,\n",
       "  1462.9606455688477,\n",
       "  1454.504776702881,\n",
       "  1446.078863067627,\n",
       "  1437.6928836669922,\n",
       "  1429.348201347351,\n",
       "  1421.0193197021486,\n",
       "  1412.7244974365235,\n",
       "  1404.4518452148438,\n",
       "  1396.2036008300781,\n",
       "  1387.9857276916505,\n",
       "  1379.8105339050294,\n",
       "  1371.6644082946777,\n",
       "  1363.5435543518067,\n",
       "  1355.431269268036,\n",
       "  1347.332639038086,\n",
       "  1339.2685572509765,\n",
       "  1331.2405622558595,\n",
       "  1323.2594194335938,\n",
       "  1315.2934475097657,\n",
       "  1307.3556615600587,\n",
       "  1299.4550627441406,\n",
       "  1291.577040725708,\n",
       "  1283.7362496337892,\n",
       "  1275.927600830078,\n",
       "  1268.1344962158203,\n",
       "  1260.3526617431642,\n",
       "  1252.6120842895507,\n",
       "  1244.8873836669923,\n",
       "  1237.1968618164062,\n",
       "  1229.525073791504,\n",
       "  1221.8837215576173,\n",
       "  1214.2444688110352,\n",
       "  1206.6302009887695,\n",
       "  1199.0554852905273,\n",
       "  1191.4991351318358,\n",
       "  1183.9746109008788,\n",
       "  1176.4719706726073,\n",
       "  1169.0152909545898,\n",
       "  1161.579666442871,\n",
       "  1154.1687045898439,\n",
       "  1146.764917236328,\n",
       "  1139.3669166259765,\n",
       "  1132.0173570098877,\n",
       "  1124.6887151184083,\n",
       "  1117.3814615020751,\n",
       "  1110.1044418945312,\n",
       "  1102.8564654083252,\n",
       "  1095.645473754883,\n",
       "  1088.480205230713,\n",
       "  1081.3299611206055,\n",
       "  1074.2028807373047,\n",
       "  1067.0923827514648,\n",
       "  1059.9886423950195,\n",
       "  1052.9139176635742,\n",
       "  1045.8554876861572,\n",
       "  1038.8249165649413,\n",
       "  1031.818648071289,\n",
       "  1024.8383865966796,\n",
       "  1017.8676699829101,\n",
       "  1010.9146213378906,\n",
       "  1003.9922114868164,\n",
       "  997.1041868591309,\n",
       "  990.2418055419922,\n",
       "  983.3973392028809,\n",
       "  976.5925658569336,\n",
       "  969.8213595886231,\n",
       "  963.062102722168,\n",
       "  956.32483694458,\n",
       "  949.6178674316407,\n",
       "  942.9247548217774,\n",
       "  936.2601180419922,\n",
       "  929.6092131347656,\n",
       "  922.9878591308594,\n",
       "  916.3797451782226,\n",
       "  909.7822857055664,\n",
       "  903.2101849365234,\n",
       "  896.6643909912109,\n",
       "  890.1440658874511,\n",
       "  883.6599731445312,\n",
       "  877.2045242614746,\n",
       "  870.7709165649414,\n",
       "  864.3559371337891,\n",
       "  857.947765625,\n",
       "  851.5591701049805,\n",
       "  845.1908735351562,\n",
       "  838.8540693969727,\n",
       "  832.526760559082,\n",
       "  826.2200275268555,\n",
       "  819.9585567321777,\n",
       "  813.7292477111816,\n",
       "  807.5298094329834,\n",
       "  801.3617877807617,\n",
       "  795.2067409057618,\n",
       "  789.0739370727539,\n",
       "  782.9754532470703,\n",
       "  776.8920145950317,\n",
       "  770.8233706054688,\n",
       "  764.7613517456055,\n",
       "  758.7192982559204,\n",
       "  752.7112656860352,\n",
       "  746.7232111206055,\n",
       "  740.7576179504395,\n",
       "  734.8192924804688,\n",
       "  728.9051740112304,\n",
       "  723.0238549194336,\n",
       "  717.1577542114258,\n",
       "  711.3165769348144,\n",
       "  705.4966970672607,\n",
       "  699.7105281982422,\n",
       "  693.9368074340821,\n",
       "  688.1851811981201,\n",
       "  682.4537281188965,\n",
       "  676.735606262207,\n",
       "  671.0458161010743,\n",
       "  665.373143371582,\n",
       "  659.7218812255859,\n",
       "  654.088370670848,\n",
       "  648.4719061279297,\n",
       "  642.8814021911621,\n",
       "  637.3199011974335,\n",
       "  631.7797292480469,\n",
       "  626.2632946166992,\n",
       "  620.7767090454101,\n",
       "  615.3112892608642,\n",
       "  609.8628590698243,\n",
       "  604.4455527038574,\n",
       "  599.0532137145996,\n",
       "  593.6848218078613,\n",
       "  588.3327719116211,\n",
       "  583.0167726440429,\n",
       "  577.7226022033691,\n",
       "  572.4434695129395,\n",
       "  567.182726928711,\n",
       "  561.9512947387695,\n",
       "  556.7384819660186,\n",
       "  551.5359501800538,\n",
       "  546.3613287353515,\n",
       "  541.1981858825684,\n",
       "  536.067324798584,\n",
       "  530.9440249633789,\n",
       "  525.8300301818848,\n",
       "  520.734842010498,\n",
       "  515.6688364105224,\n",
       "  510.62914303588866,\n",
       "  505.60136039733885,\n",
       "  500.5878507080078,\n",
       "  495.5946562805176,\n",
       "  490.6214966125488,\n",
       "  485.6704369049072,\n",
       "  480.7390169067383,\n",
       "  475.83111766052247,\n",
       "  470.94541040039064,\n",
       "  466.0915433959961,\n",
       "  461.2609217529297,\n",
       "  456.44940642738345,\n",
       "  451.6485407104492,\n",
       "  446.87313983154297,\n",
       "  442.1277095947266,\n",
       "  437.4058186683655,\n",
       "  432.70003049850465,\n",
       "  428.00997471618655,\n",
       "  423.33834951114653,\n",
       "  418.68662632751466,\n",
       "  414.0466822967529,\n",
       "  409.42875665347754,\n",
       "  404.830323348999,\n",
       "  400.25622531318663,\n",
       "  395.7022724304199,\n",
       "  391.16433737182615,\n",
       "  386.6415710906982,\n",
       "  382.1439593811035,\n",
       "  377.66595782470705,\n",
       "  373.21077627563477,\n",
       "  368.775402923584,\n",
       "  364.35910650634764,\n",
       "  359.94951075744626,\n",
       "  355.555033241272,\n",
       "  351.1848790893555,\n",
       "  346.8327110900879,\n",
       "  342.50553225708006,\n",
       "  338.19214767456054,\n",
       "  333.89749743652345,\n",
       "  329.6208293457031,\n",
       "  325.3680434265137,\n",
       "  321.1393067932129,\n",
       "  316.9303561401367,\n",
       "  312.72979420471194,\n",
       "  308.5455914916992,\n",
       "  304.37662619018556,\n",
       "  300.2315796661377]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows loss in every training\n",
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "finished-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "operating-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-complaint",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
